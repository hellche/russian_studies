[
  {
    "objectID": "index.html#динамика-и-прирост",
    "href": "index.html#динамика-и-прирост",
    "title": "I. PRODUCTION OF PUBLICATIONS",
    "section": "1. Динамика и прирост",
    "text": "1. Динамика и прирост\n\n\n\n\n\n\nTip\n\n\n\nFig 1 Использованы сущности, где статья записана одной строчкой, а не многими в случае многих авторов. Без фракционализации по SSCI или AHCI. Если исследовательская область выглядит как список, [‘SSCI’, ‘AHCI’], тогда публикация дублируется и считается как +1 публикация для каждой из областей в списке.\n\n\nНа Fig 1 видно, что публикации в [‘SSCI’] на протяжение 1990-2007 годов варьировались в диапазоне до ~400 публикаций в год. После 2008 года рубеж в 400 публикаций стабильно преодолен и количество публикаций в год нарастало вплоть до ~600 в 2020."
  },
  {
    "objectID": "index.html#динамика-по-областям",
    "href": "index.html#динамика-по-областям",
    "title": "I. PRODUCTION OF PUBLICATIONS",
    "section": "2. Динамика по областям",
    "text": "2. Динамика по областям\n\nВсе области\n\n\n\n\n\n\nTip\n\n\n\nFig 2 Использовать сущность, где статья записана одной строчкой, а не многими в случае многих авторов. Однако сделать фракционализацию на число областей. Если статья принадлежала 3 областям, то сделать 0,3 – по такому принципу. По SSCI или AHCI фракционализацию не делать.\n\n\nИз Fig 2 хорошо видно структуру Рашн стадис. Видно, что по политологии, экономики, истории и литературе написан основной массив всех текстов за 1990-2020.\n\nПоломалась интерактивностьИнтерактивнось есть на другом типе графика\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFig 4a и Fig 4b – все отлично, только сделать фракционализацию по областям. Использовать сущность, где статья записана одной строчкой, а не многими в случае многих авторов. Однако сделать фракционализацию на число областей. Если статья принадлежала 3 областям, то сделать 0,3 – по такому принципу. Оставить динамичную ось.\n\n\nНа Fig 4a и Fig 4b видно, что История сильно приросла в процентах от всех областей. Так же доля социологии, лингвистики и философии приросли. Доли Арт и литературы снизились. Очень стабильную долю на за 1990-2020 держит только политология (в районе 20%). На самом деле еще экономика, кроме всплеска доли в конце 90-х (может интерес вызван исследованиям кризиса 1998)\n\nДинамичная ось Y"
  },
  {
    "objectID": "index.html#регионы",
    "href": "index.html#регионы",
    "title": "I. PRODUCTION OF PUBLICATIONS",
    "section": "3. Регионы",
    "text": "3. Регионы\n\n\n\n\n\n\nTip\n\n\n\nFig 5a и Fig 5b Использовать сущность, где статья записана одной строчкой, а не многими в случае многих авторов. Если статья принадлежит нескольким регионам, то присвоить каждому региону статью. То есть не фракционализировать. То есть не должно быть ситуации, когда у статьи 5 авторов из России, и это 5 строчек в базе, это должна остаться 1 строчка.\n\n\nOther это Africa, Americas, Oceania.\nОсновной массив текстов раньше писался в США. Но доля США стабильно падала, доля России и Европы и Азии растет. Доля США падает не потому что они стали писать меньше статей, они пишут столько же. Это просто Россия и Европа в штуках стали больше писать.\ndistinct(UT)"
  },
  {
    "objectID": "index.html#специализация-регионов",
    "href": "index.html#специализация-регионов",
    "title": "I. PRODUCTION OF PUBLICATIONS",
    "section": "4. Специализация регионов",
    "text": "4. Специализация регионов\n\n\n\n\n\n\nTip\n\n\n\nFig 6 Использовать сущность, где статья записана одной строчкой, а не многими в случае многих авторов. Если статья принадлежит нескольким регионам, то присвоить каждому региону статью. То есть не фракционализировать. То есть не должно быть ситуации, когда у статьи 5 авторов из России, и это 5 строчек в базе, это должна остаться 1 строчка. Однако фракционализировать на число областей, то есть если статья России принадлежала 2 областям, то записать их по 0,5.\nПРИМЕР: У WOS:A1995QJ42600001 три соавтора их двух регионов. У статьи через ; две исследовательские области. Региону А в Oбласть I падает 0.5 и в Oбласть II падает 0.5. Региону В в Oбласть I падает 0.5 и в Oбласть II падает 0.5.\n\n\nНа Fig 6 в глаза бросается относительная большая специализация России на Философии, социологии, а так же относительно большая специализация США на литературе. У России в структуре относительно мало Истории, а у США экономики.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFig 7 Использовать сущность, где статья записана одной строчкой, а не многими в случае многих авторов. Если статья принадлежит нескольким регионам, то присвоить каждому региону статью. То есть не фракционализировать. То есть не должно быть ситуации, когда у статьи 5 авторов из России, и это 5 строчек в базе, это должна остаться 1 строчка. Однако фракционализировать на число областей, то есть если статья России принадлежала 2 областям, то записать их по 0,5.\n\n\nНа Fig 7 видим, что скачек доли экономических статей это в основном российский регион. Видим странный скачек Арт публикаций в России в 2005-2006. Видим планомерный рост доли истории у США. Видим странный горб по философии в 2001-2007 в России. Ну и обвал доли публикаций по политологии в России начиная с 2013. Все остальные доли в России, США и Европе кажутся относительно стабильными.\n\nСкользящее среднее + релальные значенияИнтерактивный (реальные значения)"
  },
  {
    "objectID": "index.html#вклад-региона-в-область",
    "href": "index.html#вклад-региона-в-область",
    "title": "I. PRODUCTION OF PUBLICATIONS",
    "section": "5. Вклад региона в область",
    "text": "5. Вклад региона в область\n\n\n\n\n\n\nTip\n\n\n\nFig 8a Использовать сущность, где статья записана одной строчкой, а не многими в случае многих авторов. Если статья принадлежит нескольким регионам, то присвоить каждому региону статью. То есть не фракционализировать. То есть не должно быть ситуации, когда у статьи 5 авторов из России, и это 5 строчек в базе, это должна остаться 1 строчка. Однако фракционализировать на число областей, то есть если статья России принадлежала 2 областям, то записать их по 0,5.\n\n\nРоссия из всех дисциплин серьезный вклад вносит в образование, философию, социологию и урбан (мало наблюдений) - авторы из России участвовали в написании от четверти и более всех публикаций в этих областях."
  },
  {
    "objectID": "index.html#страны-и-число-организаций",
    "href": "index.html#страны-и-число-организаций",
    "title": "I. PRODUCTION OF PUBLICATIONS",
    "section": "6. Страны и число организаций",
    "text": "6. Страны и число организаций\nПримечание: Из 33898 строк у ~8100 нет институции и у ~4200 нет страны\n\nTable 1: Страны и число организаций"
  },
  {
    "objectID": "index.html#вклад-стран-и-организаций",
    "href": "index.html#вклад-стран-и-организаций",
    "title": "I. PRODUCTION OF PUBLICATIONS",
    "section": "7. Вклад стран и организаций",
    "text": "7. Вклад стран и организаций\nПримечание: Из 33898 строк у ~8100 нет институции и у ~4200 нет страны\n\nTable 2: Most contributing countries\n\n\n\n\n\n\n\n\n\nTable 3: Most contributing institutions\n\nБез франкционализацииФранкционализация"
  },
  {
    "objectID": "about.html#средний-импакт",
    "href": "about.html#средний-импакт",
    "title": "II. IMPACT OF PIBLICATIONS",
    "section": "1. Средний импакт",
    "text": "1. Средний импакт\n\n\n\n\n\n\nTip\n\n\n\nФракционализация по общим требованиям к разделу Impact of Publications."
  },
  {
    "objectID": "about.html#страны-и-динамика-их-цитируемости",
    "href": "about.html#страны-и-динамика-их-цитируемости",
    "title": "II. IMPACT OF PIBLICATIONS",
    "section": "2. Страны и динамика их цитируемости",
    "text": "2. Страны и динамика их цитируемости\n\n\n\n\n\n\nTip\n\n\n\n\nTable 1 и Table 2 в impact of publications добавить общее N публикаций\n\n\n\nТаблица с основными странами, разделение на 3 периода и следующие показатели в каждом периоде показать: кол-во публикаций, MNSC, средняя цитируемость на статью.\n\n\n\n\n\n\nTip\n\n\n\nВажно: если у статьи два автора из россии и один с германии. Мы прибавляем +1 статью для россии (НЕ +2!) и +1 германии.\n\n\nn - число статей I - период 1990-2000 / II - период 2001-2010 / III - период 2011-2020\n\nTable 1: Страны и динамика их цитируемости"
  },
  {
    "objectID": "about.html#регионы-доли-статей-в-топах",
    "href": "about.html#регионы-доли-статей-в-топах",
    "title": "II. IMPACT OF PIBLICATIONS",
    "section": "3. Регионы: доли статей в топах",
    "text": "3. Регионы: доли статей в топах\nСредние значения показателей вхождения в топ по годам для регионов на отдельных графиках – доли статей в топе 1, 10 и 25. Три графика – линии это для регионов.\n\n\n\n\n\n\nTip\n\n\n\nФракционализация по общим требованиям к разделу Impact of Publications.\n\n\n\nСкользящее среденее + реальные значенияИнтерактивный (реальные значения)"
  },
  {
    "objectID": "about.html#страны-динамика-вхожденя-в-топ",
    "href": "about.html#страны-динамика-вхожденя-в-топ",
    "title": "II. IMPACT OF PIBLICATIONS",
    "section": "4. Страны: динамика вхожденя в топ",
    "text": "4. Страны: динамика вхожденя в топ\n\n\n\n\n\n\nTip\n\n\n\n\nTable 1 и Table 2 в impact of publications добавить общее N публикаций\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nВажно: если у статьи два автора из россии и один из германии. Мы прибавляем +1 статью для россии (НЕ +2!) и +1 германии.\n\n\nТаблица с основными странами, разделение на 3 периода и следующие показатели в каждом периоде показать: кол-во публикаций, кол-во статей в топе 1, 10 и 25 (в скобках доли статей в топе).\n\nTable 2: Страны: динамика вхожденя в топ\n\n1990-20002001-20102011-2020"
  },
  {
    "objectID": "about.html#группы-институций-показатели-51020-лучших",
    "href": "about.html#группы-институций-показатели-51020-лучших",
    "title": "II. IMPACT OF PIBLICATIONS",
    "section": "5. Группы институций: показатели 5/10/20 лучших",
    "text": "5. Группы институций: показатели 5/10/20 лучших\nСредние значения показателей по группам институций в динамике: 5,10,20 лучших, все остальные. Показатели MNSC, средняя цитируемость на статью. Линиями на графиках, а группы – это 5,10,20 лучших.\nВажно: 5 лучших в 1990 и 1991 это не обязательно одни и те же институции. В графиках показаны топы институций в каждый конкретный год. Фракционализация не производилась. Рисунки построены как лучшие по TC и mncs в каждый конкретный год. На рисунке мы фактически видим среднее средних.\nПо шагам: В 1990 году для каждой институции мы считаем среднее TC. выбираем топ 5 институций, у котрых самый высокий средний TC в 1990. Для этих 5 институции мы счимтаем средннее средних TC. Таким образом мы получаем точку, которая сейчас отображена на графике в 1990 для группы топ 5 лучших. Чтобы получить топ 10 мы берем для 10 лучших средннее средних TC (5 институций у нас те же самые что и в топ 5). Для топ 20 по тому же принципу (в топ 20 входит топ 5 и 10). Группа “все остальные” это от топ 21 места до самой последней институции. Для каждого года всё рассчитывается по новой. Для mncs всё считается отдельно по тому же принципу. На вкладках Таблица_ТС/mncs можно посмотреть конкретные значения более подробно.\n\n\n\n\n\n\nTip\n\n\n\nНет никакой фракционализации\n\n\n\nГрафикиТаблица с институциями (TC)Таблица с институциями (mncs)"
  },
  {
    "objectID": "about.html#доли-регионов-в-самом-лучшем-аутпуте",
    "href": "about.html#доли-регионов-в-самом-лучшем-аутпуте",
    "title": "II. IMPACT OF PIBLICATIONS",
    "section": "6. Доли регионов в самом лучшем аутпуте",
    "text": "6. Доли регионов в самом лучшем аутпуте\n\n\n\n\n\n\nTip\n\n\n\nв 6. Доли регионов в самом лучшем аутпуте взять доля в 10% а не доля в 25% и сделать одну общую картинку\n\n\n\n\n\n\n\n\nTip\n\n\n\nФракционализация по общим требованиям к разделу Impact of Publications.\n\n\n\nТоп 10%Топ 25%"
  },
  {
    "objectID": "about.html#доли-регионов-в-q1",
    "href": "about.html#доли-регионов-в-q1",
    "title": "II. IMPACT OF PIBLICATIONS",
    "section": "7. Доли регионов в Q1",
    "text": "7. Доли регионов в Q1\nВзять только статьи в журналах 1 квартиля в каждый из год (только с 2000 года период). Показать доли регионов по годам разными линиями. Фракционализировать по странам. Подумать, как наглядно такое показать для стран?\n\n\n\n\n\n\nTip\n\n\n\nFig.8 Не делать различия на AHCI и SSCI Фракционализация по общим требованиям к разделу Impact of Publications."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "II. IMPACT OF PIBLICATIONS",
    "section": "",
    "text": "Выброс у Азии это статья The impact of national culture and economic ideology on managerial work values: A study of the United States, Russia, Japan, and China (WOS:A1997WX87900008) где 4 соавтора и два из них из Азии. Соавторы этой статьи из других регионов растворились в среднем для своего региона того года. В Азии мало наблюдений, поэтому это выброс не растворился в среднем."
  },
  {
    "objectID": "add_tab_fidg.html#пока-не-нужно-делать",
    "href": "add_tab_fidg.html#пока-не-нужно-делать",
    "title": "III. Institutions",
    "section": "Пока не нужно делать",
    "text": "Пока не нужно делать\n\n(7) Высокий аутпут и высокий импакт. Нужны доли по процентам."
  },
  {
    "objectID": "add_tab_fig.html#пока-не-нужно-делать",
    "href": "add_tab_fig.html#пока-не-нужно-делать",
    "title": "III. INSTITUTIONS",
    "section": "Пока не нужно делать",
    "text": "Пока не нужно делать\n\n(7) Высокий аутпут и высокий импакт. Нужны доли по процентам."
  },
  {
    "objectID": "about.html#доля-региона-в-топ10-vs-доля-региона-во-всех-публикациях",
    "href": "about.html#доля-региона-в-топ10-vs-доля-региона-во-всех-публикациях",
    "title": "II. IMPACT OF PIBLICATIONS",
    "section": "8. Доля региона в топ10 vs Доля региона во всех публикациях",
    "text": "8. Доля региона в топ10 vs Доля региона во всех публикациях"
  },
  {
    "objectID": "add_tab_fig.html",
    "href": "add_tab_fig.html",
    "title": "III. INSTITUTIONS",
    "section": "",
    "text": "Tip\n\n\n\nРаздел основан на data_website_original.xlsx, а точнее на фрaкционализованном датасете на основе data_website_original.xlsx.\nУнификация связки organisation_full - country - region была осуществлена через вменение моды.\n\n\n\n\n\n\n\n\nTip\n\n\n\nОБНОВЛЕНИЕ III раздела\nДля обновления III раздела пользоваться новым файлом data_website_revised. Однако на прошлом этапе этот файл дальше преобразовывался по следующему запросу. Если код остался, то, наверное, можно повторить.\nДублирую из телеграма. Красным мои сейчас пометки:\nИзначальный датасет data_website_original (у нас сейчас data_website_revised). Прежде начала работы к нему по id добавить переменную q из data_website (думаю, что лучше брать из более полного файла full_data_precise_original переменная Q, так как в файл добавились новые строчки). - СДЕЛАНО ✅\n\n\n\n(1) Страны и организации\nМожно взять 15 стран с наибольшим вкладом. Указывается количество организаций и количество публикаций, а также процент от количества всего организаций и публикаций.\n\n\n\n\n\n\n\n\n\n(2) Топ-институций в виде графика\n\nПервый вариант графика: Давайте попробуем график со всеми точками, цветом как вы предложили > 50 и < 50. Размер кружка можно попробовать по количеству публикаций. Поделить на квадранты по средним график и показывать среднее цифрами. Из правого верхнего квадранта дать названия 10 университетам с наибольшим % в 10% публикаций.\n\n\n\n\n\n\n\nTip\n\n\n\nквадрантили сделаны средними ПО ВСЕМ ИНСТИТУЦИЯМ. пока график интерактивный, красивые статичные лейблы буду рисовать руками. сейчас всплывают все названия организаций и коорединаты по которым они построены, а так же число статей у красных точек, чтобы удобно было писать текст. Все подписи / размеры / буду делать в статике после того как мы выберем окончательный вид графика\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(3) Топ-институций\nсами значения показателей в виде таблицы. Взять университеты, которые одновременно выше среднего по 2 нашим показателям.\n\nсреднее для двух показателей, с которыми будем сравнивать (их же мы видим как mean на рис Версия 1)\n\n\n\n\n \n  \n    mean(top_10_fr_sh) \n    mean(mncs_frac_mean) \n  \n \n\n  \n    13.44597 \n    0.9430216 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n(4) Организации и динамика их вклада.\n\n\n\n\n\n\nImportant\n\n\n\nЗДЕСЬ ПОД ТОП ОРГАНИЗАЦИЯМИ (столбец our_top_org) имеются ввиду организации, которые отвечают трем требованиям:\n\n>= 50 публикаций\ntop_10_fr_sh > среднего значения top_10_fr_sh для ВСЕХ ИНСТИТУЦИЙ (НЕ ДЛЯ ИНСТИТУЦИЙ С >= 50 публикаций)\nmncs_frac_mean > среднего значения mncs_frac_mean для ВСЕХ ИНСТИТУЦИЙ (НЕ ДЛЯ ИНСТИТУЦИЙ С >= 50 публикаций)\n\n\n\nВзять наш топ организаций и показать, как по периодам (у нас их три) распределяются статьи. Мы отвечаем насколько заслуги распределены между периодами. Нет ли историй у которых были бы полностью заслуги в прошлом, но есть новички. 1990-2020 % pubs of total – это доля публикация организации взятая от всех публикаций в датасете Далее 3 колонки доля уже от 1990-2020 N pubs самой организации. Возможно лучше давать N и долю в скобках.\nНа всем датасете дать такие цифры: для каждого нашего региона посчитать среднее как для всех организаций распределяются по 3 периодам публикации. То есть будет цифра для North America сколько в среднем для ее организаций процентов публикаций вышло в первом, втором и третьем периоде.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(5) Топ организаций специализируется ли на чем-то одном?\nВ колонке указать – название области, по которой больше всего статей (2 и 3 место также), количество статей по этой области и доля публикаций от числа публикаций этой организации - name,N and %.\n\nFIELDS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResearch areas\n\n\n\n\n\n\nTip\n\n\n\nважно! на третьем месте может быть сразу две области. берется только одна. первая по алфавиту. для топовых универов такое было 1 раз.\n\n\n\n\n\n\n\n\n\nПрицепить к всплывающему лейблу название области не так просто, поэтому только смоетреть в таблице.\n\n\n\n\n\n\n\n\n\n(6) По всем ли периодам был одинаковый топ?\n\n\n\n\n\n\nImportant\n\n\n\nДля этогих задач был сделан новый датасет с фракционализацией, так как у нас показатели цитируемости и top раньше рассчитывались для всего периода 1990-2020.\nДля групп 1990-2000,  2001-2010, 2011-2020 показатель total_pub >=50 на основе которого мы, в том числе определяем топ, превращается в total_pub >= 16.66 (то есть, 50 / 3) для соответствующего периода 1990-2000,  2001-2010, 2011-2020.\n\n\nЕсли попробовать разбить датасет по нашим периодам и по нашему алгоритму найти для каждого периода свой список вузов, которые попали в четвертый квадрат (выше среднего и по нормализованной цитируемости и по доле публикаций в 10%). Тогда результат вот так можно представить. И может быть подсветить цветом название вуза (из числа наших топов за весь период), если он был в этот период в топе.\n\n\n\n\n \n  \n    mean(top_10_fr_sh) \n    mean(mncs_frac_mean) \n    period \n  \n \n\n  \n    13.44597 \n    0.9430216 \n    1990-2020 \n  \n  \n    14.43272 \n    1.0981965 \n    1990-2000 \n  \n  \n    12.62818 \n    0.9093282 \n    2001-2010 \n  \n  \n    12.95818 \n    0.8252276 \n    2011-2020 \n  \n\n\n\n\n\n\nСписок TOP организаций по алфавитуСписок TOP организаций с показателями\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nИ еще нужна такая простая табличка. Дать список наших университетов и сколько раз они попали в топ за три периода (то есть максимальное количество 3 должно быть).\n\n\n\n\n\n\nTip\n\n\n\nмаксимальное значение 4, так как по принятым критериям попадания в топ, попадание в топ в диапазоне, например, 1990-2000 не значит, что институция попала в топ всего периода 1990-2020."
  },
  {
    "objectID": "index.html#отдельные-цифры-для-отчета",
    "href": "index.html#отдельные-цифры-для-отчета",
    "title": "I. PRODUCTION OF PUBLICATIONS",
    "section": "8. Отдельные цифры для отчета",
    "text": "8. Отдельные цифры для отчета\n\n\n\n\nОбщее число уникальных статей 1990-2020: 25851. Общее число строк 1990-2020: 33898\nTotal Russian studies output has increased N%, for the 30-year period covering 1990-2020: рост AHCI за 30 лет = 38.2%, рост SSCI за 30 лет = 81.7%. Без разбиения на fields, общий рост 55.1%. Что НЕ равно (%SSCI + %AHCI) / 2, тут нет ошибки.\n\nКОММЕНТАРИЙ, О КАКОМ ПРИРОСТЕ ИДЕТ РЕЧЬ:\nВ 1990 году было 100 статей, в 1991 уже 110. У нас произошел рост на 10%.\nВ 1992 году у нас было 110 статей. Значит роста не было, так как мы сравниваем уже не с 1990, а 1991. Значит 10% + 0%.\nВ 1993 было 105 статей, значит по сравнению с 110 в 1992 (которые для нас теперь 100%) это \\(100 * 105 / 110 = 95.45455.\\) Меньше на 4.545%. Итого за три года рост был \\(10% + 0% - 4.545%\\)\nВАЖНО! Синяя линия на графике не про эти проценты, такая линия у нас была на первой версии гит странички, мы решили ее не показывать, она супер хаотично выглядит. Если что цифра, которую требуется вставить в текст это сумма по годам этих скачущих процентов:\n\n\n\n\n\n\n\n\n\nfor the 30-year period covering 1990–2020 the value of MNCS for Northern America publications is N (we can also observe that the recent papers tend to be cited less often – in 1990-2010 the MNCS was N while in 2011-2020 - N), the MNCS score for the European papers is N.\n\n\nв среднем MNCS в сша 1990–2020: 1.3\nпо периодам США и Европа:\n\n\n\n\n\n \n  \n    year_3 \n    region \n    mean_mncs \n  \n \n\n  \n    1990-2010 \n    Europe \n    1 \n  \n  \n    2011-2020 \n    Europe \n    1 \n  \n  \n    1990-2010 \n    Northern America \n    1 \n  \n  \n    2011-2020 \n    Northern America \n    1 \n  \n\n\n\n\n\n\nFor instance, in the period 1990-2000, the proportion of Northern America’s papers which were not cited was N, in 2000-2010 – N and in 2011-2020 – N. It seems that former articles are not cited because they are considered as obsolete while recent papers have not yet gained attention but they have chances to be cited in the forthcoming years. Although, in general, Russian papers demonstrate the same pattern, proportion of non-cited papers tend to be higher, especially in the first and second periods: in 1990- 2000, 2001-2010 – N and in 2011-2020 – N. In the last five years, Russia has showed the steady decrease in the proportion of non-cited articles.\n\n\n\n# A tibble: 6 × 3\n  year_group region           sh_zero_cit\n  <chr>      <chr>                  <dbl>\n1 1990-2000  Northern America        25.9\n2 2001-2010  Northern America        15.2\n3 2011-2020  Northern America        30.8\n4 1990-2000  Russia                  51.7\n5 2001-2010  Russia                  31.4\n6 2011-2020  Russia                  32.6\n\n\n\nНужен график как выше – доля статей в Q1 для региона для 2000-2020 годов. Fig.9\n\n\nЭтот лежит в папке на гугле\n\n\n\n\n\n\n\n\nдля удобства анализа"
  },
  {
    "objectID": "Untitled.html",
    "href": "Untitled.html",
    "title": "Russian Studies",
    "section": "",
    "text": "data %>% distinct(UT, .keep_all = TRUE) %>% \n  select(UT, year, research_areas) %>% \n  \n  # разворачиваем research_areas\n  separate_rows(research_areas, sep=\";\") %>% \n  mutate(research_areas = str_trim(research_areas, \"both\")) %>% \n  mutate(frac = 1) %>% group_by(UT) %>% \n  mutate(frac = 1/ length(research_areas)) %>% ungroup() %>% \n  \n  group_by(research_areas) %>%\n  mutate(research_areas = case_when(sum(frac) < 400 ~ \"Other\",\n                                    TRUE ~ research_areas)) %>% ungroup() %>%\n  group_by(year, research_areas) %>% \n  summarise(n = sum(frac)) %>%  ungroup() %>% \n  group_by(year) %>% \n  mutate(perc = round(100 * n / sum(n), 2)) %>% ungroup() %>% \n  mutate(research_areas = factor(research_areas, levels = areas)) %>% \n  ggplot(aes(x = as.character(year), y = perc, fill = research_areas)) + \n  # geom_col(alpha = 0.8 , size = 0.2, colour = \"white\") +\n  geom_col(alpha = 0.7 , size = 0.1, colour = \"black\") +\n  # geom_col(alpha = 0.8 , size = 0.2) +\n  scale_y_continuous(labels = function(x) paste0(x, \"%\")) +\n  guides(fill = guide_legend(keyheight = 0.6, keywidth = 0.6)) + \n  labs(fill = \"\") +\n  scale_fill_manual(values = my_color, limits = force) +\n  theme_test() +\n  theme(panel.grid = element_blank(),\n        axis.title = element_blank(),\n        axis.text.x = element_text(size = 8, angle = 90, vjust = 0.5),\n        axis.text.y = element_text(size = 8),\n        legend.justification = \"top\")\n\nggsave(filename = \"Fig2.tiff\",\n       family=\"Helvetica\",\n       units = \"mm\", dpi = 600,  width = 174,\n       height = 86)\n\n```"
  },
  {
    "objectID": "add_staff.html",
    "href": "add_staff.html",
    "title": "IV. ADD STAFF",
    "section": "",
    "text": "Tip\n\n\n\nЭто дополнительные расчеты, для заполнение пустот в Text for the site analytics.pdf Прям по порядку по тексту.\n\n\n\n\n\n\nОбщее число уникальных статей 1990-2020: 25851. Общее число строк 1990-2020: 33898\nTotal Russian studies output has increased N%, for the 30-year period covering 1990-2020: рост AHCI за 30 лет = 38.2082378%, рост SSCI за 30 лет = 81.7373796%. Без разбиения на fields, общий рост 55.10437%. Что НЕ равно (%SSCI + %AHCI) / 2, тут нет ошибки.\n\nКОММЕНТАРИЙ, О КАКОМ ПРИРОСТЕ ИДЕТ РЕЧЬ:\nВ 1990 году было 100 статей, в 1991 уже 110. У нас произошел рост на 10%.\nВ 1992 году у нас было 110 статей. Значит роста не было, так как мы сравниваем уже не с 1990, а 1991. Значит 10% + 0%.\nВ 1993 было 105 статей, значит по сравнению с 110 в 1992 (которые для нас теперь 100%) это \\(100 * 105 / 110 = 95.45455.\\) Меньше на 4.545%. Итого за три года рост был \\(10% + 0% - 4.545%\\)\nВАЖНО! Синяя линия на графике не про эти проценты, такая линия у нас была на первой версии гит странички, мы решили ее не показывать, она супер хаотично выглядит. Если что цифра, которую требуется вставить в текст это сумма по годам этих скачущих процентов:\n\n\n\n\n\n\n\n\n\nfor the 30-year period covering 1990–2020 the value of MNCS for Northern America publications is N (we can also observe that the recent papers tend to be cited less often – in 1990-2010 the MNCS was N while in 2011-2020 - N), the MNCS score for the European papers is N.\n\n\nв среднем MNCS в сша 1990–2020: 1.27\nпо периодам США и Европа:\n\n\n\n\n\n \n  \n    year_3 \n    region \n    mean_mncs \n  \n \n\n  \n    1990-2010 \n    Europe \n    1.12 \n  \n  \n    2011-2020 \n    Europe \n    1.13 \n  \n  \n    1990-2010 \n    Northern America \n    1.38 \n  \n  \n    2011-2020 \n    Northern America \n    1.07 \n  \n\n\n\n\n\n\nFor instance, in the period 1990-2000, the proportion of Northern America’s papers which were not cited was N, in 2000-2010 – N and in 2011-2020 – N. It seems that former articles are not cited because they are considered as obsolete while recent papers have not yet gained attention but they have chances to be cited in the forthcoming years. Although, in general, Russian papers demonstrate the same pattern, proportion of non-cited papers tend to be higher, especially in the first and second periods: in 1990- 2000, 2001-2010 – N and in 2011-2020 – N. In the last five years, Russia has showed the steady decrease in the proportion of non-cited articles.\n\n\n\n# A tibble: 6 × 3\n  year_group region           sh_zero_cit\n  <chr>      <chr>                  <dbl>\n1 1990-2000  Northern America        25.9\n2 2001-2010  Northern America        15.2\n3 2011-2020  Northern America        30.8\n4 1990-2000  Russia                  51.7\n5 2001-2010  Russia                  31.4\n6 2011-2020  Russia                  32.6\n\n\n\nНужен график как выше – доля статей в Q1 для региона для 2000-2020 годов. Fig.9\n\n\nЭтот лежит в папке на гугледля удобства анализа\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData from citations provide a window into the impact of a region’s scientific production to the most cited output (Fig.10). In 1990-s the Northern America was the major contributor to the world’s pool of 10% top cited articles – almost all articles were published by authors from this region. With the growth of papers written by European researchers the share has started to decrease: the Northern America was 46 for 2008 and 25.4807692 for 2020.\n\n2015, Europe region overtaken the Northern America in the relative participation in the Top 10% – the region accounts for the 40% 43.3333333 of all top articles while Northern America – 28% 30.8333333 The proportion of Russian articles also increased from 1990 to 2020 from 1.1235955 to 22.5961538. The next Fig. 11 shows that publication of top cited articles is related to the publishing in high quality journals – the same pattern can be seen regarding the region’s share of papers published in Q1 journals.\n\n\n\n\n\n\nWarning\n\n\n\nДо этого момента все расчеты приводились на основе full_data_precise_original. То есть это раличные дополнения по материалам I и II раздела сайта. Следующий пункт (8) посчитан на data_website_original.xlsx, а точнее на фрaкционализованном датасете на основе data_website_original.xlsx. То есть теперь у нас поудет допонение к III разделу сайта.\n\n\n\n\n\n\n\n\n\nThe final dataset includes 428 organizations from 33 different countries (institutions which have contributed at least 10 articles were considered).\nВЕРНОЕ УТВЕРЖДЕНИЕ: For instance, if a publication has 4authors of which two belong to a particular organization, the publication for this organization is counted withaweightof2/4=0.5."
  },
  {
    "objectID": "add_staff.html#phd-ка-text",
    "href": "add_staff.html#phd-ка-text",
    "title": "IV. ADD STAFF",
    "section": "phd-ка Text",
    "text": "phd-ка Text\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nЭто дополнительные расчеты, для заполнение пустот в Text for the site analytics.pdf Прям по порядку по тексту.\n\n\n\n\n\n\nОбщее число уникальных статей 1990-2020: 25851. Общее число строк 1990-2020: 33898\nTotal Russian studies output has increased N%, for the 30-year period covering 1990-2020: рост AHCI за 30 лет = 38.2082378%, рост SSCI за 30 лет = 81.7373796%. Без разбиения на fields, общий рост 55.10437%. Что НЕ равно (%SSCI + %AHCI) / 2, тут нет ошибки.\n\nКОММЕНТАРИЙ, О КАКОМ ПРИРОСТЕ ИДЕТ РЕЧЬ:\nВ 1990 году было 100 статей, в 1991 уже 110. У нас произошел рост на 10%.\nВ 1992 году у нас было 110 статей. Значит роста не было, так как мы сравниваем уже не с 1990, а 1991. Значит 10% + 0%.\nВ 1993 было 105 статей, значит по сравнению с 110 в 1992 (которые для нас теперь 100%) это \\(100 * 105 / 110 = 95.45455.\\) Меньше на 4.545%. Итого за три года рост был \\(10% + 0% - 4.545%\\)\nВАЖНО! Синяя линия на графике не про эти проценты, такая линия у нас была на первой версии гит странички, мы решили ее не показывать, она супер хаотично выглядит. Если что цифра, которую требуется вставить в текст это сумма по годам этих скачущих процентов:\n\n\n\n\n\n\n\n\n\nfor the 30-year period covering 1990–2020 the value of MNCS for Northern America publications is N (we can also observe that the recent papers tend to be cited less often – in 1990-2010 the MNCS was N while in 2011-2020 - N), the MNCS score for the European papers is N.\n\n\nв среднем MNCS в сша 1990-2020:\nпо периодам США и Европа:\n\n\n\n\n\n \n  \n    year_3 \n    region \n    mean_mncs \n  \n \n\n  \n    1990-2010 \n    Europe \n    1.12 \n  \n  \n    2011-2020 \n    Europe \n    1.13 \n  \n  \n    1990-2010 \n    Northern America \n    1.38 \n  \n  \n    2011-2020 \n    Northern America \n    1.07 \n  \n\n\n\n\n\n\nFor instance, in the period 1990-2000, the proportion of Northern America’s papers which were not cited was N, in 2000-2010 – N and in 2011-2020 – N. It seems that former articles are not cited because they are considered as obsolete while recent papers have not yet gained attention but they have chances to be cited in the forthcoming years. Although, in general, Russian papers demonstrate the same pattern, proportion of non-cited papers tend to be higher, especially in the first and second periods: in 1990- 2000, 2001-2010 – N and in 2011-2020 – N. In the last five years, Russia has showed the steady decrease in the proportion of non-cited articles.\n\n\n\n# A tibble: 6 × 3\n  year_group region           sh_zero_cit\n  <chr>      <chr>                  <dbl>\n1 1990-2000  Northern America        25.9\n2 2001-2010  Northern America        15.2\n3 2011-2020  Northern America        30.8\n4 1990-2000  Russia                  51.7\n5 2001-2010  Russia                  31.4\n6 2011-2020  Russia                  32.6\n\n\n\nНужен график как выше – доля статей в Q1 для региона для 2000-2020 годов. Fig.9\n\n\nЭтот лежит в папке на гугледля удобства анализа\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData from citations provide a window into the impact of a region’s scientific production to the most cited output (Fig.10). In 1990-s the Northern America was the major contributor to the world’s pool of 10% top cited articles – almost all articles were published by authors from this region. With the growth of papers written by European researchers the share has started to decrease: the Northern America was 46 for 2008 and 25.4807692 for 2020.\n\n2015, Europe region overtaken the Northern America in the relative participation in the Top 10% – the region accounts for the 40% 43.3333333 of all top articles while Northern America – 28% 30.8333333 The proportion of Russian articles also increased from 1990 to 2020 from 1.1235955 to 22.5961538. The next Fig. 11 shows that publication of top cited articles is related to the publishing in high quality journals – the same pattern can be seen regarding the region’s share of papers published in Q1 journals.\n\nWhile Russia is one of key players on the global research scene, as the country produced in 2020 about N percent of the Russian studies articles included in the WoS, the impact of articles is below world average.\n\n\n\n# A tibble: 5 × 3\n  region               n    sh\n  <chr>            <int> <dbl>\n1 Asia               112  8.62\n2 Europe             480 37.0 \n3 Northern America   360 27.7 \n4 Other               47  3.62\n5 Russia             300 23.1 \n\n\n\n\n# A tibble: 1 × 1\n      n\n  <int>\n1  1156\n\n\n\n\n\n\n\n\nWarning\n\n\n\nДо этого момента все расчеты приводились на основе full_data_precise_original. То есть это раличные дополнения по материалам I и II раздела сайта. Следующий пункт (8) посчитан на data_website_original.xlsx, а точнее на фрaкционализованном датасете на основе data_website_original.xlsx. То есть теперь у нас поудет допонение к III разделу сайта."
  },
  {
    "objectID": "add_staff.html#файл-с-таблицами-tables-for-site",
    "href": "add_staff.html#файл-с-таблицами-tables-for-site",
    "title": "IV. ADD STAFF",
    "section": "Файл с таблицами Tables for site",
    "text": "Файл с таблицами Tables for site\nkaterina guba, [15 февр. 2023г., 20:06:35]: Тут только не забыть, что сейчас на сайте все, что странами ( до таблицы 3) сделано на полном датасете с необрезанными организациями, а с таблицы 3 на датасете, где только организации для сайта 428.\nТо есть табличка 3 такая пограничная, она про страны но с инфо по организациям поэтому ее на обрезанном датасете.\nВсе таблички с организациями на обрезанном\n\n1\n\n\n\n\n\n\nTip\n\n\n\nВажно: если у статьи два автора из россии и один с германии. Мы прибавляем +1 статью для россии (НЕ +2) и +1 германии.\nполный датасет\n\n\ncountry 1990-2020 N\n1990-2020 total (%) 1990-2020 cumulative total (%)\n1990 N 1990 total (%)\n2020 N 2020 total (%)\n\n\n\n\n\n2\ncountry\n1990-2020N\nTotal Citations\nmncs_I mncs_II mncs_III\nt1% (share) t10% (share) t25% (share) - у страны 100 статей и t1% = 10, значит из 100 10 статей в топ1 % of non-cited articles\n\n\n\n\n\n3\n\n\n\n\n\n\nTip\n\n\n\nобрезанный датасет\n\n\ncountry\n1990-2020 N publications\n1990-2020 % publications of total\n1990-2020 N organizations\n1990-2020 % organizations of total Average N papers per organization N orgs in 1990\nN orgs in 2020\n\n\n\n\n\n4\n\n\n\n\n\n\nTip\n\n\n\nобрезанный датасет\n\n\nOrganizations\nCountry\ntotal_pub\nmncs_frac_mean top_10_fr_sh\nTop1 Top2\n\nВ списке должно быть 79 органищаций, у которых больше 50 публ\ntop1 - это входит ли в список 49 у которых больше по двум средним показателям и top2 - это входит в верхний квартиль по 2 показателям (то есть берутся не выше среднего а выше показателя 75% организаций), у меня получалось 25 организаций"
  },
  {
    "objectID": "about.html#для-pdf-ки",
    "href": "about.html#для-pdf-ки",
    "title": "II. IMPACT OF PIBLICATIONS",
    "section": "9. Для pdf-ки",
    "text": "9. Для pdf-ки\n\n\n\n\n\n\nTip\n\n\n\nВажно: если у статьи два автора из россии и один из германии. Мы прибавляем +1 статью для россии (НЕ +2!) и +1 германии."
  },
  {
    "objectID": "data_website_plus_full.html",
    "href": "data_website_plus_full.html",
    "title": "Russian Studies",
    "section": "",
    "text": "library(viridis)\n\nЗагрузка требуемого пакета: viridisLite\n\nlibrary(scales)\n\n\nПрисоединяю пакет: 'scales'\n\n\nСледующий объект скрыт от 'package:viridis':\n\n    viridis_pal\n\nlibrary(ggrepel)\n\nЗагрузка требуемого пакета: ggplot2\n\nlibrary(tidyverse)\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n✔ purrr   1.0.0      \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n\nlibrary(expss)\n\nЗагрузка требуемого пакета: maditr\n\nTo aggregate several columns with one summary: take(mtcars, mpg, hp, fun = mean, by = am)\n\n\nПрисоединяю пакет: 'maditr'\n\nСледующие объекты скрыты от 'package:dplyr':\n\n    between, coalesce, first, last\n\nСледующий объект скрыт от 'package:purrr':\n\n    transpose\n\nСледующий объект скрыт от 'package:readr':\n\n    cols\n\n\nПрисоединяю пакет: 'expss'\n\nСледующие объекты скрыты от 'package:stringr':\n\n    fixed, regex\n\nСледующие объекты скрыты от 'package:dplyr':\n\n    compute, contains, na_if, recode, vars\n\nСледующие объекты скрыты от 'package:purrr':\n\n    keep, modify, modify_if, when\n\nСледующие объекты скрыты от 'package:tidyr':\n\n    contains, nest\n\nСледующий объект скрыт от 'package:ggplot2':\n\n    vars\n\nlibrary(FactoMineR)\nlibrary(factoextra)\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\nlibrary(RColorBrewer)\nlibrary(stringr)\nlibrary(stringi)\nlibrary(haven)\n\n\nПрисоединяю пакет: 'haven'\n\nСледующие объекты скрыты от 'package:expss':\n\n    is.labelled, read_spss\n\nlibrary(readr)\nlibrary(table1)\n\n\nПрисоединяю пакет: 'table1'\n\nСледующие объекты скрыты от 'package:base':\n\n    units, units<-\n\nlibrary(sjlabelled)\n\n\nПрисоединяю пакет: 'sjlabelled'\n\nСледующие объекты скрыты от 'package:haven':\n\n    as_factor, read_sas, read_spss, read_stata, write_sas, zap_labels\n\nСледующий объект скрыт от 'package:expss':\n\n    read_spss\n\nСледующий объект скрыт от 'package:forcats':\n\n    as_factor\n\nСледующий объект скрыт от 'package:dplyr':\n\n    as_label\n\nСледующий объект скрыт от 'package:ggplot2':\n\n    as_label\n\nlibrary(ggpubr)\n\n\nПрисоединяю пакет: 'ggpubr'\n\nСледующий объект скрыт от 'package:expss':\n\n    compare_means\n\nlibrary(ggridges)\nlibrary(ggsignif)\nlibrary(patchwork)\nlibrary(tibble)\nlibrary(ggpmisc)\n\nЗагрузка требуемого пакета: ggpp\n\nПрисоединяю пакет: 'ggpp'\n\nСледующий объект скрыт от 'package:ggplot2':\n\n    annotate\n\nlibrary(readxl)\nlibrary(data.table)\n\n\nПрисоединяю пакет: 'data.table'\n\nСледующие объекты скрыты от 'package:expss':\n\n    copy, like\n\nСледующие объекты скрыты от 'package:maditr':\n\n    copy, dcast, melt\n\nСледующие объекты скрыты от 'package:dplyr':\n\n    between, first, last\n\nСледующий объект скрыт от 'package:purrr':\n\n    transpose\n\nlibrary(ggthemes)\nlibrary(knitr)\n# options(kableExtra.latex.load_packages = FALSE)\nlibrary(kableExtra)\n\n\nПрисоединяю пакет: 'kableExtra'\n\nСледующий объект скрыт от 'package:dplyr':\n\n    group_rows\n\nlibrary(DT)\nlibrary(tidyquant)\n\nЗагрузка требуемого пакета: lubridate\nЗагрузка требуемого пакета: timechange\n\nПрисоединяю пакет: 'lubridate'\n\nСледующие объекты скрыты от 'package:data.table':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\nСледующие объекты скрыты от 'package:base':\n\n    date, intersect, setdiff, union\n\nЗагрузка требуемого пакета: PerformanceAnalytics\nЗагрузка требуемого пакета: xts\nЗагрузка требуемого пакета: zoo\n\nПрисоединяю пакет: 'zoo'\n\nСледующие объекты скрыты от 'package:base':\n\n    as.Date, as.Date.numeric\n\n\nПрисоединяю пакет: 'xts'\n\nСледующие объекты скрыты от 'package:data.table':\n\n    first, last\n\nСледующие объекты скрыты от 'package:maditr':\n\n    first, last\n\nСледующие объекты скрыты от 'package:dplyr':\n\n    first, last\n\n\nПрисоединяю пакет: 'PerformanceAnalytics'\n\nСледующий объект скрыт от 'package:graphics':\n\n    legend\n\nЗагрузка требуемого пакета: quantmod\nЗагрузка требуемого пакета: TTR\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\nlibrary(plotly)\n\n\nПрисоединяю пакет: 'plotly'\n\nСледующий объект скрыт от 'package:ggplot2':\n\n    last_plot\n\nСледующий объект скрыт от 'package:stats':\n\n    filter\n\nСледующий объект скрыт от 'package:graphics':\n\n    layout\n\nlibrary(ggalt)\n\nRegistered S3 methods overwritten by 'ggalt':\n  method                  from   \n  grid.draw.absoluteGrob  ggplot2\n  grobHeight.absoluteGrob ggplot2\n  grobWidth.absoluteGrob  ggplot2\n  grobX.absoluteGrob      ggplot2\n  grobY.absoluteGrob      ggplot2\n\n\n\nЗадача 1: восстаналиваем строки в data_website\n\nfull_data <- read_excel(\"data/data_21_feb_2023/full_data.xlsx\") %>% \n    mutate(organisation_full = case_when(is.na(organisation_full) ~ \"Unknown\",\n                                         TRUE ~ organisation_full)) %>% \n    mutate(sourse = \"full_data\") #%>% \n  #   group_by(organisation_full) %>%\n  #   mutate(n_pub = length(UT),\n  #          n_pub_uni = length(unique(UT))) %>% ungroup() %>% \n  # filter(n_pub_uni >= 10) %>% \n  # filter(organisation_full != \"Unknown\")\n\ndata_website <- read_excel(\"data/data_21_feb_2023/data_website.xlsx\") %>% \n    mutate(organisation_full = case_when(is.na(organisation_full) ~ \"Unknown\",\n                                         TRUE ~ organisation_full)) %>% \n    mutate(sourse = \"data_website\")\n\n\ndf1 <- data_website %>% \n  select(UT, organisation_full) %>% \n  group_by(UT) %>% \n  mutate(n_coaut_web = length(UT)) %>% ungroup() %>% \n  distinct(UT, n_coaut_web)\n\ndf2 <- full_data %>% \n  select(UT, organisation_full) %>% \n  group_by(UT) %>% \n  mutate(n_coaut_full = length(UT)) %>% ungroup() %>% \n  distinct(UT, n_coaut_full)\n\ndf <- left_join(df2, df1)\n\nJoining, by = \"UT\"\n\ndf <- df %>% \n  mutate(n_coaut_web = case_when(is.na(n_coaut_web) ~ as.numeric(0),\n                                 TRUE ~ as.numeric(n_coaut_web))) %>% \n  mutate(diff = n_coaut_full - n_coaut_web)\n\ndf <- df %>% select(UT, diff)\n\nadd <- rep(df$UT, times=df$diff)\nadd <- data_frame(UT = add)\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nℹ Please use `tibble()` instead.\n\n# add <- add %>%  group_by(UT) %>% \n#   mutate(n_coaut_web = length(UT)) %>% ungroup() \nrm(df2,df1,df)\n\n# data <- rbind(data_website %>%   \n#                select(UT, sourse) %>% \n#                group_by(UT) %>% \n#                mutate(n_coaut_web = length(UT)) %>% ungroup(), \n#              add %>% mutate(sourse = \"add\"))\n\nДанные data_website_plus_full.csv: основа data_website к которому добавлены строки с соответствующим UT, так, что бы их количество совпадало с full_data. Столбец sourse принимает два значения: “add from full_data” или “data_website”. Таким образом можно понять из какого дататета были запослнены соответствующие строки. Для строк “add from full_data” organisation_full всегда принимает занчение “Unknown or Uni < 10” и country всегда “Unknown”.\nВажно: переменная collab_type никак не менялась, возможно она неправильная.\n\ndf <- full_data %>% select(-organisation_full, -country, -sourse) %>% \n  distinct(UT, .keep_all = TRUE)\nadd <- add %>% left_join(df) %>% \n  mutate(country = \"Unknown\",\n         organisation_full = \"Unknown or Uni < 10\",\n         sourse = \"add from full_data\")\n\nJoining, by = \"UT\"\n\nrm(df)\n\ndata_website_plus_full <- rbind(data_website, add)\n\n# df <- data_website_plus_full %>% group_by(UT) %>% \n#    mutate(n_coaut_web = length(UT)) %>% ungroup() \n\nwrite_csv(data_website_plus_full, \"data_website_plus_full.csv\")\n\n\n\nЗадача 2: Катерине для ручной проверки\nДанные full_data_code_list основан на full_data. К full_data добавлены AF, C1 из data_website_full.\nПотенциально если в переменной organisation_full_2 стоит “Uni < 10” или “Unknown”, то это хвост, который обрезан в данных data_website.\nПеременные code_ - коды в 4 и > цифр из C1.\n\nfull_data_2 <- read_excel(\"data/data_21_feb_2023/full_data.xlsx\") %>%\n    mutate(organisation_full = case_when(is.na(organisation_full) ~ \"Unknown\",\n                                         TRUE ~ organisation_full)) %>%\n    group_by(organisation_full) %>%\n    mutate(n_pub_uni = length(UT)) %>% ungroup() %>%\n    mutate(organisation_full_2 = case_when(n_pub_uni < 10 ~ \"Uni < 10\",\n                                           TRUE ~ organisation_full))\n\ndata_website_full <- read_excel(\"data/data_21_feb_2023/data_website_full.xlsx\")\n\ndf <- data_website_full %>% \n  distinct(UT, .keep_all = TRUE) %>% \n  select(UT, AF, C1) \n\nfull_data_code_list <- full_data_2 %>% left_join(df)\n\nJoining, by = \"UT\"\n\ndf <- data_website_full %>% \n  distinct(UT, .keep_all = TRUE) %>% \n  select(UT, AF, C1) %>% \n  # mutate(code_ = stringr::str_extract_all(C1, \"[0-9]{4,11}\", simplify = TRUE)) # %>% \n  # mutate(ex2 = stringr::str_extract_all(C1, \"([A-Za-z0-9]+(-[A-Za-z0-9]{4,11}+)+)\"))\n  mutate(code = stringr::str_extract_all(C1, \"[0-9]{4,11}\")) %>% \n  unnest(code) %>% \n  group_by(UT) %>%  \n  mutate(statute = paste0('code_', row_number())) %>% \n  spread(statute, code) %>% \n  select(\"UT\",\n    \"code_1\", \"code_2\", \"code_3\", \"code_4\", \"code_5\", \"code_6\",\n    \"code_7\", \"code_8\", \"code_9\", \"code_10\", \"code_11\", \"code_12\",\n    \"code_13\")\n\nfull_data_code_list <- full_data_code_list %>% left_join(df)\n\nJoining, by = \"UT\"\n\nwrite_csv(full_data_code_list, \"full_data_code_list.csv\")\n\nДанные data_website_code_list основан на data_website. К data_website добавлены AF, C1 из data_website_full.\nПеременные code_ - коды в 4 и > цифр из C1.\n\ndata_website_2 <- read_excel(\"data/data_21_feb_2023/data_website.xlsx\") %>% \n    mutate(organisation_full = case_when(is.na(organisation_full) ~ \"Unknown\",\n                                         TRUE ~ organisation_full)) \n\ndf <- data_website_full %>% \n  distinct(UT, .keep_all = TRUE) %>% \n  select(UT, AF, C1) \n\ndata_website_code_list <- data_website_2 %>% left_join(df)\n\nJoining, by = \"UT\"\n\ndf <- data_website_full %>% \n  distinct(UT, .keep_all = TRUE) %>% \n  select(UT, AF, C1) %>% \n  # mutate(code_ = stringr::str_extract_all(C1, \"[0-9]{4,11}\", simplify = TRUE)) # %>% \n  # mutate(ex2 = stringr::str_extract_all(C1, \"([A-Za-z0-9]+(-[A-Za-z0-9]{4,11}+)+)\"))\n  mutate(code = stringr::str_extract_all(C1, \"[0-9]{4,11}\")) %>% \n  unnest(code) %>% \n  group_by(UT) %>%  \n  mutate(statute = paste0('code_', row_number())) %>% \n  spread(statute, code) %>% \n  select(\"UT\",\n    \"code_1\", \"code_2\", \"code_3\", \"code_4\", \"code_5\", \"code_6\",\n    \"code_7\", \"code_8\", \"code_9\", \"code_10\", \"code_11\", \"code_12\",\n    \"code_13\")\n\ndata_website_code_list <- data_website_code_list %>% left_join(df)\n\nJoining, by = \"UT\"\n\nwrite_csv(data_website_code_list, \"data_website_code_list.csv\")"
  },
  {
    "objectID": "чистка_афиляций_базового_файла.html",
    "href": "чистка_афиляций_базового_файла.html",
    "title": "Russian Studies",
    "section": "",
    "text": "library(viridis)\n\nЗагрузка требуемого пакета: viridisLite\n\nlibrary(scales)\n\n\nПрисоединяю пакет: 'scales'\n\n\nСледующий объект скрыт от 'package:viridis':\n\n    viridis_pal\n\nlibrary(ggrepel)\n\nЗагрузка требуемого пакета: ggplot2\n\nlibrary(tidyverse)\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n✔ purrr   1.0.0      \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n\nlibrary(expss)\n\nЗагрузка требуемого пакета: maditr\n\nTo aggregate several columns with one summary: take(mtcars, mpg, hp, fun = mean, by = am)\n\n\nПрисоединяю пакет: 'maditr'\n\nСледующие объекты скрыты от 'package:dplyr':\n\n    between, coalesce, first, last\n\nСледующий объект скрыт от 'package:purrr':\n\n    transpose\n\nСледующий объект скрыт от 'package:readr':\n\n    cols\n\n\nПрисоединяю пакет: 'expss'\n\nСледующие объекты скрыты от 'package:stringr':\n\n    fixed, regex\n\nСледующие объекты скрыты от 'package:dplyr':\n\n    compute, contains, na_if, recode, vars\n\nСледующие объекты скрыты от 'package:purrr':\n\n    keep, modify, modify_if, when\n\nСледующие объекты скрыты от 'package:tidyr':\n\n    contains, nest\n\nСледующий объект скрыт от 'package:ggplot2':\n\n    vars\n\nlibrary(FactoMineR)\nlibrary(factoextra)\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\nlibrary(RColorBrewer)\nlibrary(stringr)\nlibrary(stringi)\nlibrary(haven)\n\n\nПрисоединяю пакет: 'haven'\n\nСледующие объекты скрыты от 'package:expss':\n\n    is.labelled, read_spss\n\nlibrary(readr)\nlibrary(table1)\n\n\nПрисоединяю пакет: 'table1'\n\nСледующие объекты скрыты от 'package:base':\n\n    units, units<-\n\nlibrary(sjlabelled)\n\n\nПрисоединяю пакет: 'sjlabelled'\n\nСледующие объекты скрыты от 'package:haven':\n\n    as_factor, read_sas, read_spss, read_stata, write_sas, zap_labels\n\nСледующий объект скрыт от 'package:expss':\n\n    read_spss\n\nСледующий объект скрыт от 'package:forcats':\n\n    as_factor\n\nСледующий объект скрыт от 'package:dplyr':\n\n    as_label\n\nСледующий объект скрыт от 'package:ggplot2':\n\n    as_label\n\nlibrary(ggpubr)\n\n\nПрисоединяю пакет: 'ggpubr'\n\nСледующий объект скрыт от 'package:expss':\n\n    compare_means\n\nlibrary(ggridges)\nlibrary(ggsignif)\nlibrary(patchwork)\nlibrary(tibble)\nlibrary(ggpmisc)\n\nЗагрузка требуемого пакета: ggpp\n\nПрисоединяю пакет: 'ggpp'\n\nСледующий объект скрыт от 'package:ggplot2':\n\n    annotate\n\nlibrary(readxl)\nlibrary(data.table)\n\n\nПрисоединяю пакет: 'data.table'\n\nСледующие объекты скрыты от 'package:expss':\n\n    copy, like\n\nСледующие объекты скрыты от 'package:maditr':\n\n    copy, dcast, melt\n\nСледующие объекты скрыты от 'package:dplyr':\n\n    between, first, last\n\nСледующий объект скрыт от 'package:purrr':\n\n    transpose\n\nlibrary(ggthemes)\nlibrary(knitr)\n# options(kableExtra.latex.load_packages = FALSE)\nlibrary(kableExtra)\n\n\nПрисоединяю пакет: 'kableExtra'\n\nСледующий объект скрыт от 'package:dplyr':\n\n    group_rows\n\nlibrary(DT)\nlibrary(tidyquant)\n\nЗагрузка требуемого пакета: lubridate\nЗагрузка требуемого пакета: timechange\n\nПрисоединяю пакет: 'lubridate'\n\nСледующие объекты скрыты от 'package:data.table':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\nСледующие объекты скрыты от 'package:base':\n\n    date, intersect, setdiff, union\n\nЗагрузка требуемого пакета: PerformanceAnalytics\nЗагрузка требуемого пакета: xts\nЗагрузка требуемого пакета: zoo\n\nПрисоединяю пакет: 'zoo'\n\nСледующие объекты скрыты от 'package:base':\n\n    as.Date, as.Date.numeric\n\n\nПрисоединяю пакет: 'xts'\n\nСледующие объекты скрыты от 'package:data.table':\n\n    first, last\n\nСледующие объекты скрыты от 'package:maditr':\n\n    first, last\n\nСледующие объекты скрыты от 'package:dplyr':\n\n    first, last\n\n\nПрисоединяю пакет: 'PerformanceAnalytics'\n\nСледующий объект скрыт от 'package:graphics':\n\n    legend\n\nЗагрузка требуемого пакета: quantmod\nЗагрузка требуемого пакета: TTR\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\nlibrary(plotly)\n\n\nПрисоединяю пакет: 'plotly'\n\nСледующий объект скрыт от 'package:ggplot2':\n\n    last_plot\n\nСледующий объект скрыт от 'package:stats':\n\n    filter\n\nСледующий объект скрыт от 'package:graphics':\n\n    layout\n\nlibrary(ggalt)\n\nRegistered S3 methods overwritten by 'ggalt':\n  method                  from   \n  grid.draw.absoluteGrob  ggplot2\n  grobHeight.absoluteGrob ggplot2\n  grobWidth.absoluteGrob  ggplot2\n  grobX.absoluteGrob      ggplot2\n  grobY.absoluteGrob      ggplot2\n\n\nУ нас есть UT WOS:000078889900001\n000466168000004\nЕсть 2 файла с одинаковой структурой полностью (только внутри одна переменная иначе кодируется - про коллаборации, а в остальном набор переменных тот же - может быть перекодировать сначала, чтобы одинаковы были файлы).\ndata_website - это для сайта. Короткий обрезанный файл.\nfull_data - это полные данные, включая обрезанные организации. Длинный необрезанный.\n\nДавайте добавим обрезанные раньше наблюдения из full_data в data_website.\n\nЯ не совсем пока понимаю, как их точно идентифицировать - обрезанные могут UT иметь такой же, как и оставшиеся наблюдения (если соавтора автора удалили из статьи). Но наверное можно сличить все переменные и найти все наблюдения, которые повторяются в другом датасете и добавить все остальные.\nВажно добавленные переменные обозначить в виде переменной - deleted\n\nfull_data <- read_excel(\"data/data_21_feb_2023/full_data.xlsx\") %>% \n  select(UT, organisation_full) %>% \n  # mutate(organisation_full = str_trim(organisation_full, side = \"both\"),\n  #        organisation_full = str_replace_all(organisation_full, \"[^[:alnum:]]\", \" \"),\n  #        organisation_full = tolower(organisation_full),\n  #        organisation_full = gsub(\"[[:space:]]\", \"_\", organisation_full),\n  #        organisation_full = gsub(\"[[:blank:]]\", \"_\", organisation_full)) %>% \n  #group_by(UT) %>% \n  #mutate(full_n_coaut = length(UT)) %>% ungroup() %>% \n   # \n   # mutate(sourse = \"full_data\",\n   #        id = paste0(\"fd_\", row_number())) %>% \n  filter(UT == \"WOS:000356603200004\")\n#write_csv(full_data, \"df1.csv\")\n\ndata_website <- read_excel(\"data/data_21_feb_2023/data_website.xlsx\") %>% \n  select(UT, organisation_full) %>% \n  # mutate(organisation_full = str_trim(organisation_full, side = \"both\"),\n  #        organisation_full = str_replace_all(organisation_full, \"[^[:alnum:]]\", \" \"),\n  #        organisation_full = tolower(organisation_full),\n  #        organisation_full = gsub(\"[[:space:]]\", \"_\", organisation_full),\n  #        organisation_full = gsub(\"[[:blank:]]\", \"_\", organisation_full)) %>% \n  #group_by(UT) %>% \n  #mutate(web_n_coaut = length(UT)) %>% ungroup() %>% \n  \n  # mutate(sourse = \"data_website\",\n  #        id = paste0(\"dw_\", row_number())) %>% \n  filter(UT == \"WOS:000356603200004\") %>% \n  filter(organisation_full == \"Aalto University\")\n\n# write_csv(data_website, \"df2.csv\")\n#df1 <- read_csv(\"df1.csv\")\n#df2 <- read_csv(\"df2.csv\")\n#df <- left_join(df1, df2) %>% group_by(UT, organisation_full) %>% count()\nlj <- left_join(data_website, full_data, by = c(\"UT\"))\nfj <- full_join(data_website, full_data, by = c(\"UT\", \"organisation_full\"))\nij <- full_join(data_website, full_data)\n\nJoining, by = c(\"UT\", \"organisation_full\")\n\ndf <- full_join(full_data, data_website, \n                by = c(\"UT\")) %>% \n  group_by(UT) %>% \n  mutate(n_coaut = length(UT)) %>% ungroup() #%>% \n # filter(UT == \"WOS:000506001200041\")\n  # mutate(status = case_when(n_coaut == web_n_coaut & n_coaut == full_n_coaut ~ \"full both\",\n  #                           \n  #                           TRUE ~ NA_character_))\n\n\n# убираем NA organisation_full data_website\ndata_website_NA <- data_website %>% filter(is.na(organisation_full))\ndata_website_long <- data_website %>% filter(!is.na(organisation_full))\n\n# вычлиняем NA organisation_full full_data\nfull_data_NA <- full_data %>% filter(is.na(organisation_full)) \n\n# цепляем к data_website NA из full_data\ndata_website_long <- rbind(data_website_long, full_data_NA)\nrm(full_data_NA)\n\n# цепляем к data_website NA из data_website\ndata_website_long <- rbind(data_website_long, data_website_NA)\nrm(data_website_NA)\n\n\n\n\n\nfull_data <- read_excel(\"data/data_21_feb_2023/full_data.xlsx\") %>% \n  select(UT, organisation_full) %>% \n  group_by(organisation_full) %>% \n  mutate(n_pub_org = length(UT)) %>% ungroup()\n\nnew <- full_data %>% filter(!is.na(organisation_full)) %>% \n  filter(n_pub_org >= 10)\n\ndata_website <- read_excel(\"data/data_21_feb_2023/data_website.xlsx\") %>% \n  select(UT, organisation_full) \n\n\nК новому файлу прикрепить из data_website_full переменные AF C1 Это переменные об авторах и адресе и они в строчки записаны, поэтому для всех статей в соавторстве эти переменные будут совпадать для всех авторов.\nВ строчке адреса есть индексы, но не у всех. попробовать сделать новую переменную с индексом (к примеру задать, что найди числовую сущность из не менее 4 цифр и выдели ее отдельно. В строчке может быть несколько индексов и тогда наверное несколько переменных с индексом получится.\nКак-то так пока.\n\n\ndata_website_full <- read_excel(\"data/data_21_feb_2023/data_website_full.xlsx\") %>% \n  select(UT, organisation_full, AF, C1)\n\nmy_text <- \"the number 5849 and 5555555555 shouldn't turn up. but12345654 and 99119911 should be. let's see if 1234567H also works. It shouldn't. both 12345678JE and RG10293847 should turn up as well.\"\nstringr::str_extract_all(my_text, \"\\\\d{4}\")#[[1]]\n\n[[1]]\n [1] \"5849\" \"5555\" \"5555\" \"1234\" \"5654\" \"9911\" \"9911\" \"1234\" \"1234\" \"5678\"\n[11] \"1029\" \"3847\"\n\ndf <- data_website_full %>% mutate(ex = stringr::str_extract_all(C1, \"[0-9]{4,11}\")) %>% \n  mutate(ex2 = stringr::str_extract_all(C1, \"([A-Za-z0-9]+(-[A-Za-z0-9]{4,11}+)+)\"))\n\n\ndf2 <- df %>% group_by(ex) %>% count()\ndf3 <- df %>% group_by(ex2) %>% count()"
  },
  {
    "objectID": "institution_fractionalization_hand.html",
    "href": "institution_fractionalization_hand.html",
    "title": "Russian Studies",
    "section": "",
    "text": "код на основе файла fractionalization_institutions.Rmd\nпо новому запросту от Катерины:\nИзначальный датасет data_website_original (у нас сейчас data_website_revised). Прежде начала работы к нему по id добавить переменную q из data_website (думаю, что лучше брать из более полного файла full_data_precise_original переменная Q, так как в файл добавились новые строчки).\nНиже описана задача как получение 2 файлов, с фракционализацией и без фракционализации. Но удобнее получить один файл, где будут институции наблюдением, а переменные будут представлены как фракционализированные так и нет.\n\nlibrary(viridis)\n\nLoading required package: viridisLite\n\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:viridis':\n\n    viridis_pal\n\nlibrary(ggrepel)\n\nLoading required package: ggplot2\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ lubridate 1.9.2     ✔ tibble    3.2.1\n✔ purrr     1.0.1     ✔ tidyr     1.3.0\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\nlibrary(expss)\n\nLoading required package: maditr\n\nTo aggregate several columns with one summary: take(mtcars, mpg, hp, fun = mean, by = am)\n\n\nAttaching package: 'maditr'\n\nThe following objects are masked from 'package:dplyr':\n\n    between, coalesce, first, last\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n\nThe following object is masked from 'package:readr':\n\n    cols\n\n\nAttaching package: 'expss'\n\nThe following objects are masked from 'package:stringr':\n\n    fixed, regex\n\nThe following objects are masked from 'package:dplyr':\n\n    compute, contains, na_if, recode, vars, where\n\nThe following objects are masked from 'package:purrr':\n\n    keep, modify, modify_if, when\n\nThe following objects are masked from 'package:tidyr':\n\n    contains, nest\n\nThe following object is masked from 'package:ggplot2':\n\n    vars\n\nlibrary(FactoMineR)\nlibrary(factoextra)\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\nlibrary(RColorBrewer)\nlibrary(stringr)\nlibrary(stringi)\nlibrary(haven)\n\n\nAttaching package: 'haven'\n\nThe following objects are masked from 'package:expss':\n\n    is.labelled, read_spss\n\nlibrary(readr)\nlibrary(table1)\n\n\nAttaching package: 'table1'\n\nThe following objects are masked from 'package:base':\n\n    units, units<-\n\nlibrary(sjlabelled)\n\n\nAttaching package: 'sjlabelled'\n\nThe following objects are masked from 'package:haven':\n\n    as_factor, read_sas, read_spss, read_stata, write_sas, zap_labels\n\nThe following object is masked from 'package:expss':\n\n    read_spss\n\nThe following object is masked from 'package:forcats':\n\n    as_factor\n\nThe following object is masked from 'package:dplyr':\n\n    as_label\n\nThe following object is masked from 'package:ggplot2':\n\n    as_label\n\nlibrary(ggpubr)\n\n\nAttaching package: 'ggpubr'\n\nThe following object is masked from 'package:expss':\n\n    compare_means\n\nlibrary(ggridges)\nlibrary(ggsignif)\nlibrary(patchwork)\nlibrary(tibble)\nlibrary(ggpmisc)\n\nLoading required package: ggpp\n\nAttaching package: 'ggpp'\n\nThe following object is masked from 'package:ggplot2':\n\n    annotate\n\nlibrary(readxl)\nlibrary(data.table)\n\n\nAttaching package: 'data.table'\n\nThe following objects are masked from 'package:expss':\n\n    copy, like\n\nThe following objects are masked from 'package:maditr':\n\n    copy, dcast, melt\n\nThe following objects are masked from 'package:lubridate':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n\nlibrary(ggthemes)\nlibrary(knitr)\n# options(kableExtra.latex.load_packages = FALSE)\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nlibrary(DT)\nlibrary(tidyquant)\n\nLoading required package: PerformanceAnalytics\nLoading required package: xts\nLoading required package: zoo\n\nAttaching package: 'zoo'\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\nAttaching package: 'xts'\n\nThe following objects are masked from 'package:data.table':\n\n    first, last\n\nThe following objects are masked from 'package:maditr':\n\n    first, last\n\nThe following objects are masked from 'package:dplyr':\n\n    first, last\n\n\nAttaching package: 'PerformanceAnalytics'\n\nThe following object is masked from 'package:graphics':\n\n    legend\n\nLoading required package: quantmod\nLoading required package: TTR\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nlibrary(ggalt)\n\nRegistered S3 methods overwritten by 'ggalt':\n  method                  from   \n  grid.draw.absoluteGrob  ggplot2\n  grobHeight.absoluteGrob ggplot2\n  grobWidth.absoluteGrob  ggplot2\n  grobX.absoluteGrob      ggplot2\n  grobY.absoluteGrob      ggplot2\n\n\n\n# data_website_original <- read_excel(\"data/data_website original.xlsx\")\ndata_website_original <- read_excel(\"data/data_website_revised.xlsx\") %>% \n  mutate(mncs = as.numeric(mncs))\n# data_website <- read_excel(\"data/data_website.xlsx\") \ndata_website <- read_excel(\"data/full_data_precise original.xlsx\") %>% \n  rename(id = UT)\n\ndata_website <- data_website %>% select(id, Q) %>% \n  distinct(id, .keep_all = TRUE)\n  # group_by(id) %>% \n  # summarise(count = length(Q),\n  #           Q = paste(sort(unique(Q)), collapse = \"; \")) %>%\n  # arrange(desc(count))\n\ncountry_region <- read_csv(\"data/data_clean.csv\") \n\nRows: 33898 Columns: 27\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (16): UT, TI, journal_name, AU, AF, issn, Q, WC, research_areas, collab_...\ndbl (11): year, n_authors, author_order, core, TC, top_10, top_25, mncs, new...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncountry_region <- country_region %>% select(country, region) %>%\n  distinct(country, region, .keep_all = TRUE) %>%\n  filter(!is.na(country))\n\ndata_kat <- data_website_original %>% \n  left_join(data_website, by = c(\"UT\" = \"id\")) %>% \n  mutate(year_group = case_when(year >= 1990 & year <= 2000 ~ \"1990-2000\",\n                                year >= 2001 & year <= 2010 ~ \"2001-2010\",\n                                year >= 2011 & year <= 2020 ~ \"2011-2020\",\n                                TRUE ~ as.character(year))) %>% \n  mutate(year_group = factor(year_group, \n                             levels = c(\"1990-2000\", \"2001-2010\",\"2011-2020\"))) \ndata_kat$country[data_kat$country == \"Hong Kong\"] <- \"China\"\ndata_kat <- data_kat %>% left_join(country_region)\n\nJoining with `by = join_by(country)`"
  },
  {
    "objectID": "institution_fractionalization_hand.html#переменные",
    "href": "institution_fractionalization_hand.html#переменные",
    "title": "Russian Studies",
    "section": "Переменные",
    "text": "Переменные\n1990-2000 - количество публикаций этой организации 2001-2010 - количество публикаций этой организации 2011-2020 – количество публикаций этой организации country - Страна region - Регион\n\ndf1 <- data_non_frac %>% \n  group_by(organisation_full) %>% \n  summarise(total_pub = length(UT),\n            country = paste(sort(unique(country)),collapse=\"; \"),\n            region = paste(sort(unique(region)),collapse=\"; \"))\ndf2 <- data_non_frac %>% \n  group_by(organisation_full, year_group) %>% \n  summarise(count = length(organisation_full)) %>% \n  pivot_wider(values_from = \"count\", names_from = \"year_group\") %>% \n  ungroup() %>% \n  select(organisation_full, `1990-2000`, `2001-2010`, `2011-2020`) \n\n`summarise()` has grouped output by 'organisation_full'. You can override using\nthe `.groups` argument.\n\ndata <- left_join(df1, df2)  \n\nJoining with `by = join_by(organisation_full)`\n\n\nq1 – количество статей в 1 квартиле q2 – количество статей в 2 квартиле q3 – количество статей в 3 квартиле q4 – количество статей в 4 квартиле q1_2000_2020 - количество статей в 1 квартиле в периоде 2000-2020\n\ndf1 <- data_non_frac %>% \n  group_by(organisation_full, Q) %>% \n  summarise(count = length(organisation_full)) %>% \n  pivot_wider(values_from = \"count\", names_from = \"Q\") %>% \n  ungroup() %>% \n  select(organisation_full, `Q1`, `Q2`, `Q3`, `Q4`, `NA`) \n\n`summarise()` has grouped output by 'organisation_full'. You can override using\nthe `.groups` argument.\n\ndf2 <- data_non_frac %>% \n  filter(Q == \"Q1\") %>% \n  filter(year >= 2000) %>% \n  group_by(organisation_full) %>% \n  summarise(q1_2000_2020 = length(organisation_full))\n\ndf3 <- df1 %>% left_join(df2)\n\nJoining with `by = join_by(organisation_full)`\n\ndata <- data %>% left_join(df3)\n\nJoining with `by = join_by(organisation_full)`\n\n\nresearch_areas - 15 переменных и в них количество публикаций организации в этой категории. Если нескольким категориям, то присвоить часть статьи. Фракционализовать.\n\ndf1 <- data_non_frac %>% select(UT, organisation_full, research_areas) %>% \n  mutate(id = row_number()) %>% \n  separate_rows(research_areas, sep=\";\") %>% \n  mutate(research_areas = str_trim(research_areas, \"both\")) %>% \n  group_by(id) %>% \n  mutate(n_fields = length(organisation_full)) %>% ungroup() %>% select(-id) %>% \n  mutate(frac_fields = 1 / n_fields) %>% \n  group_by(organisation_full, research_areas) %>% \n  summarise(count = sum(frac_fields)) %>% ungroup() %>% \n  pivot_wider(values_from = \"count\", names_from = \"research_areas\") \n\n`summarise()` has grouped output by 'organisation_full'. You can override using\nthe `.groups` argument.\n\ndata <- data %>% left_join(df1)\n\nJoining with `by = join_by(organisation_full)`\n\n\nfield - 3 переменных SSCI, AHCI, SSCI/AHCI – и число публикаций в каждой категории\n\ndf1 <- data_non_frac %>% \n  group_by(organisation_full, field) %>% \n  summarise(count = length(organisation_full)) %>% \n  pivot_wider(values_from = \"count\", names_from = \"field\") %>% \n  ungroup() \n\n`summarise()` has grouped output by 'organisation_full'. You can override using\nthe `.groups` argument.\n\ndata <- data %>% left_join(df1)\n\nJoining with `by = join_by(organisation_full)`\n\n\nTC - взять среднее для организации по всему датасету top_1 - взять сумму для организации по всему датасету top_10 - взять сумму для организации по всему датасету top_25 - взять сумму для организации по всему датасету mncs - взять среднее для организации по всему датасету\n\ndf1 <- data_non_frac %>% \n  group_by(organisation_full) %>% \n  summarise(TC = mean(TC, na.rm = TRUE),\n            top_1 = sum(top_1),\n            top_10 = sum(top_10),\n            top_25 = sum(top_25),\n            mncs = mean(mncs, na.rm = TRUE)) \n\ndata <- data %>% left_join(df1)\n\nJoining with `by = join_by(organisation_full)`\n\n\ncollab_type – категориальные переменные с число публикаций по каждой категории collab_type\n\ndf1 <- data_non_frac %>% \n  group_by(organisation_full, collab_type) %>% \n  summarise(count = length(organisation_full)) %>% \n  pivot_wider(values_from = \"count\", names_from = \"collab_type\") %>% \n  ungroup() \n\n`summarise()` has grouped output by 'organisation_full'. You can override using\nthe `.groups` argument.\n\ndata <- data %>% left_join(df1)\n\nJoining with `by = join_by(organisation_full)`\n\nwrite_csv(data, \"data_non_frac_hand.csv\")\nopenxlsx::write.xlsx(data, \"data_non_frac_hand.xlsx\")"
  },
  {
    "objectID": "institution_fractionalization_hand.html#переменные-1",
    "href": "institution_fractionalization_hand.html#переменные-1",
    "title": "Russian Studies",
    "section": "Переменные",
    "text": "Переменные\n1990-2000 - количество публикаций этой организации * С учетом фракционализации 2001-2010 - количество публикаций этой организации * С учетом фракционализации 2011-2020 – количество публикаций этой организации * С учетом фракционализации country - Страна region - Регион\n\ndf1 <- data_frac %>% \n  group_by(organisation_full) %>% \n  summarise(total_pub = sum(frac),\n            country = paste(sort(unique(country)),collapse=\"; \"),\n            region = paste(sort(unique(region)),collapse=\"; \"))\ndf2 <- data_frac %>% \n  group_by(organisation_full, year_group) %>% \n  summarise(count = sum(frac)) %>% \n  pivot_wider(values_from = \"count\", names_from = \"year_group\") %>% \n  ungroup() %>% \n  select(organisation_full, `1990-2000`, `2001-2010`, `2011-2020`) \n\n`summarise()` has grouped output by 'organisation_full'. You can override using\nthe `.groups` argument.\n\ndata <- left_join(df1, df2)  \n\nJoining with `by = join_by(organisation_full)`\n\n\nq1 – количество статей в 1 квартиле *если статья 1 квартиля была половинкой статьи в результате фракционализации, то и здесь она считается половинкой. Ко всем квартилям это относится. q2 – количество статей в 2 квартиле q3 – количество статей в 3 квартиле q4 – количество статей в 4 квартиле q1_2000_2020 - количество статей в 1 квартиле в периоде 2000-2020\n\ndf1 <- data_frac %>% \n  group_by(organisation_full, Q) %>% \n  summarise(count = sum(frac)) %>% \n  pivot_wider(values_from = \"count\", names_from = \"Q\") %>% \n  ungroup() %>% \n  select(organisation_full, `Q1`, `Q2`, `Q3`, `Q4`, `NA`) \n\n`summarise()` has grouped output by 'organisation_full'. You can override using\nthe `.groups` argument.\n\ndf2 <- data_frac %>% \n  filter(Q == \"Q1\") %>% \n  filter(year >= 2000) %>% \n  group_by(organisation_full) %>% \n  summarise(q1_2000_2020 = sum(frac))\n\ndf3 <- df1 %>% left_join(df2)\n\nJoining with `by = join_by(organisation_full)`\n\ndata <- data %>% left_join(df3)\n\nJoining with `by = join_by(organisation_full)`\n\n\nresearch_areas - 15 переменных и в них количество публикаций организации в этой категории. Если нескольким категориям, то присвоить часть статьи. Фракционализовать.\n\ndf1 <- data_frac %>% select(UT, organisation_full, frac, research_areas) %>% \n  mutate(id = row_number()) %>% \n  separate_rows(research_areas, sep = \";\") %>% \n  mutate(research_areas = str_trim(research_areas, \"both\")) %>% \n  group_by(id) %>% \n  mutate(n_fields = length(organisation_full)) %>% ungroup() %>% select(-id) %>% \n  mutate(frac_fields = 1 / n_fields) %>% \n  # filter(UT == \"WOS:000286815100004\" | UT == \"WOS:000356603200004\") %>% \n  group_by(UT, organisation_full, research_areas, frac) %>% \n  summarise(count = sum(frac_fields)) %>% ungroup() %>% \n  group_by(organisation_full, research_areas) %>% \n  mutate(frac_frac = frac * count) %>% \n  ungroup() %>% \n  group_by(organisation_full, research_areas) %>% \n  summarise(frac_frac_frac = sum(frac_frac)) %>% ungroup() %>% \n  pivot_wider(values_from = \"frac_frac_frac\", names_from = \"research_areas\") \n\n`summarise()` has grouped output by 'UT', 'organisation_full',\n'research_areas'. You can override using the `.groups` argument.\n`summarise()` has grouped output by 'organisation_full'. You can override using\nthe `.groups` argument.\n\ndata <- data %>% left_join(df1)\n\nJoining with `by = join_by(organisation_full)`\n\n\nfield - 3 переменных SSCI, AHCI, SSCI/AHCI – и число публикаций в каждой категории\n\ndf1 <- data_frac %>% \n  group_by(organisation_full, field) %>% \n  summarise(count = sum(frac)) %>% \n  pivot_wider(values_from = \"count\", names_from = \"field\") %>% \n  ungroup() \n\n`summarise()` has grouped output by 'organisation_full'. You can override using\nthe `.groups` argument.\n\ndata <- data %>% left_join(df1)\n\nJoining with `by = join_by(organisation_full)`\n\n\nФракционализация TC и mncs и top\n\n# Проба Фракционализации TC\n\ndf1 <- data_frac %>% select(UT, organisation_full, frac, TC) %>%\n  filter(UT == \"WOS:000286815100004\" | UT == \"WOS:000356603200004\" | UT == \"WOS:000085344600006\") %>%\n  # mutate(paper = case_when(UT == \"WOS:000286815100004\" ~ \"A\",\n  #                          UT == \"WOS:000356603200004\" ~ \"B\",\n  #                          TRUE ~ \"C\"), .before = \"UT\") %>%\n\n  mutate(TC_f = TC * frac) %>%\n  # group_by(organisation_full) %>%\n  # mutate(pp = length(unique(UT))) %>% ungroup() %>%\n  group_by(organisation_full, UT) %>%\n  summarise(TC_fsum = sum(TC_f, na.rm = TRUE)) %>% ungroup() %>%\n  group_by(organisation_full) %>%\n  summarise(TC_fmean = mean(TC_fsum, na.rm = TRUE))\n\n`summarise()` has grouped output by 'organisation_full'. You can override using\nthe `.groups` argument.\n\ndf2 <- data_non_frac %>%\n  filter(UT == \"WOS:000286815100004\" | UT == \"WOS:000356603200004\" | UT == \"WOS:000085344600006\") %>%\n  group_by(organisation_full) %>%\n  summarise(TC = mean(TC, na.rm = TRUE))\n            \ndf2 <- df2 %>% left_join(df1)\n\nJoining with `by = join_by(organisation_full)`\n\ndata_frac %>% select(UT, organisation_full, frac, TC) %>%\n  filter(UT == \"WOS:000286815100004\" | UT == \"WOS:000356603200004\" | UT == \"WOS:000085344600006\") %>%\n  mutate(TC_f = TC * frac) %>%\n  group_by(organisation_full) %>%\n  mutate(pp = length(unique(UT))) %>% ungroup() %>%\n  mutate(pp_f = pp * frac) %>%\n  group_by(organisation_full, UT) %>%\n  mutate(TC_fsum = mean(TC_f, na.rm = TRUE)) %>% ungroup() %>%\n  group_by(organisation_full) %>%\n  summarise(TC_fmean = sum(TC_fsum, na.rm = TRUE) / pp_f)\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n`summarise()` has grouped output by 'organisation_full'. You can override using\nthe `.groups` argument.\n\n\n# A tibble: 9 × 2\n# Groups:   organisation_full [4]\n  organisation_full             TC_fmean\n  <chr>                            <dbl>\n1 Aalto University                 43.6 \n2 Aalto University                 43.6 \n3 Aalto University                 58.2 \n4 Aalto University                 58.2 \n5 Aalto University                 58.2 \n6 University of Helsinki            7.17\n7 University of Helsinki           10.8 \n8 University of Western Ontario    29   \n9 Unknown or Uni < 10               7   \n\ndf2 <- df2 %>% left_join(df1)\n\nJoining with `by = join_by(organisation_full, TC_fmean)`\n\n# write_csv(df1, \"df1.csv\")\n\n\n# Фракционализация TC\ndf1 <- data_frac %>% select(UT, organisation_full, frac, TC) %>% \n  # filter(UT == \"WOS:000286815100004\" | UT == \"WOS:000356603200004\" | UT == \"WOS:000085344600006\") %>% \n  mutate(TC_f = TC * frac) %>% \n  # group_by(organisation_full) %>% \n  # mutate(pp = length(unique(UT))) %>% ungroup() %>% \n  group_by(organisation_full, UT) %>% \n  summarise(TC_fsum = sum(TC_f, na.rm = TRUE)) %>% ungroup() %>% \n  group_by(organisation_full) %>% \n  summarise(TC_frac_mean = mean(TC_fsum, na.rm = TRUE))\n\n`summarise()` has grouped output by 'organisation_full'. You can override using\nthe `.groups` argument.\n\ndata <- data %>% left_join(df1)\n\nJoining with `by = join_by(organisation_full)`\n\n# Фракционализация mncs\ndf1 <- data_frac %>% select(UT, organisation_full, frac, mncs) %>% \n  # filter(UT == \"WOS:000286815100004\" | UT == \"WOS:000356603200004\" | UT == \"WOS:000085344600006\") %>% \n  mutate(mncs_f = mncs * frac) %>% \n  # group_by(organisation_full) %>% \n  # mutate(pp = length(unique(UT))) %>% ungroup() %>% \n  group_by(organisation_full, UT) %>% \n  summarise(mncs_fsum = sum(mncs_f, na.rm = TRUE)) %>% ungroup() %>% \n  group_by(organisation_full) %>% \n  summarise(mncs_frac_mean = mean(mncs_fsum, na.rm = TRUE))\n\n`summarise()` has grouped output by 'organisation_full'. You can override using\nthe `.groups` argument.\n\ndata <- data %>% left_join(df1)\n\nJoining with `by = join_by(organisation_full)`\n\n## Фракционализация top_\n\ndf1 <- data_frac %>% select(UT, organisation_full, frac, starts_with(\"top_\")) %>% \n  # filter(UT == \"WOS:000286815100004\" | UT == \"WOS:000356603200004\" | UT == \"WOS:000085344600006\") %>% \n  mutate(top_1_fr = top_1 * frac,\n         top_10_fr = top_10 * frac,\n         top_25_fr = top_25 * frac,\n         top_50_fr = top_50 * frac) %>% \n  group_by(organisation_full) %>% \n  summarise(top_1_fr = sum(top_1_fr),\n            top_10_fr = sum(top_10_fr),\n            top_25_fr = sum(top_25_fr),\n            top_50_fr = sum(top_50_fr))\n\ndata <- data %>% left_join(df1)\n\nJoining with `by = join_by(organisation_full)`\n\n\ncollab_type – категориальные переменные с число публикаций по каждой категории collab_type\n\ndf1 <- data_frac %>% \n  group_by(organisation_full, collab_type) %>% \n  summarise(count = sum(frac)) %>% \n  pivot_wider(values_from = \"count\", names_from = \"collab_type\") %>% \n  ungroup() \n\n`summarise()` has grouped output by 'organisation_full'. You can override using\nthe `.groups` argument.\n\ndata <- data %>% left_join(df1)\n\nJoining with `by = join_by(organisation_full)`\n\nwrite_csv(data, \"data_frac_hand.csv\")\nopenxlsx::write.xlsx(data, \"data_frac_hand.xlsx\")"
  },
  {
    "objectID": "get_fixed_dataset_May2023.html",
    "href": "get_fixed_dataset_May2023.html",
    "title": "Russian Studies",
    "section": "",
    "text": "Получения full_hand_org.csv В этом файле идет получение данных для пересчета сайта. Тут надо новый вручную вычещенный катериной датасет прицепить к старому полному.\nТут идет полчная очиска как в data_clean, с точными ussr и менением моды по странм-институциям, аккураной работой с армйскими универми сша\nЕсть файл full_data_precise_original на котором делались последние расчеты для аналитики. И есть новый файл data_website_revised - это файл для анализа институций с улучшенной припиской аффилиаций и с включением строк, где организация не идентифицирована (Unknown or Uni < 10) для точной фракционализации.\n\nlibrary(readxl)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\n\n\nfull_data_precise_original <- read_excel(\"data/full_data_precise original.xlsx\")\nrevised <- read_excel(\"data/data_website_revised.xlsx\") %>% mutate(mncs = as.numeric(mncs))\n\nВ файле full_data_precise_original с 30 000 надо заменить 22 800 из data_website_revised\nДостаем 9 UT, которые надо отслеживать руками ОСТАВИМ НА ПОТОМ\n\ndf1 <- full_data_precise_original %>% select(UT) %>% \n  group_by(UT) %>% count() %>% \n  mutate(revised = \"full\")\ndf2 <- revised %>% select(UT) %>% \n  group_by(UT) %>% count() %>% \n  mutate(revised = \"revised\")\n\ndf <- left_join(df1, df2, by = c(\"UT\"))\n\ndf$n.y[is.na(df$n.y)] <- 0\n\ndf <- df %>% mutate(check = n.x - n.y) \nnine_hand <- df %>% filter(revised.y == \"revised\" & check > 0) %>% pull(UT)\n#nine_hand_full <- full_data_precise_original %>% filter(UT %in% nine_hand)# %>% \n  #select(UT, organisation_full, country)\n#nine_hand_revised <- revised %>% filter(UT %in% nine_hand) #%>% \n    #select(UT, organisation_full, country)\n#write_csv(nine_hand_full, \"nine_hand_full.csv\")\n#write_csv(nine_hand_revised, \"nine_hand_revised.csv\")\n\nВАЖНО! имя конкретного автора не совадает с его институцией в переменной organisation_revised. То есть у нас есть статья с тремя соавторами. имя - organisation - organisation_revised Ивановым - Вышка - РАН Пертровым - РАН - РАН Сидоровым - РАН - Вышка\nНо общее кол-во строчек и институций / стран сохранияется. просто фамилии теперь перемешаны\n\n## правим 9 ut\n\nfull_hand_org <- full_data_precise_original %>% # filter(!(UT %in% nine_hand)) %>% \n  select(-region) %>% \n  group_by(UT) %>% mutate(n_id = row_number()) %>% ungroup() \n\ndf1 <- revised %>% filter(!(UT %in% nine_hand)) \n\nnine_hand_revised_HAND_ADD <- read_delim(\"data/nine_hand_revised_HAND_ADD.csv\", \n    delim = \";\", escape_double = FALSE, trim_ws = TRUE) %>% mutate(mncs = as.numeric(mncs))\n\nRows: 22 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (8): UT, issn, journal_name, organisation_full, country, collab_type, re...\ndbl (8): year, TC, top_1, top_10, top_25, top_50, mncs, n_authors\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndf <- rbind(df1, nine_hand_revised_HAND_ADD)\ndf1 <- df %>% select(UT, organisation_full, country) %>% \n  group_by(UT) %>% mutate(n_id = row_number()) %>% ungroup() %>% \n  rename(org_rev = organisation_full,\n         country_rev = country)\n\nfull_hand_org <- left_join(full_hand_org, df1, by = c(\"UT\", \"n_id\"))\n\nfull_hand_org <- full_hand_org %>% \n  mutate(org_new = case_when(is.na(org_rev) ~ organisation_full,\n                             TRUE ~ org_rev)) %>%\n  mutate(country_new = case_when(!is.na(country_rev) ~ country_rev,\n                                 TRUE ~ country))\n\n\nfull_hand_org <- full_hand_org %>% \n  select(-organisation_full, -org_rev, -country, -country_rev, -n_id) %>% \n  rename(organisation_full = org_new,\n         country = country_new)\n\n# Сделали чистый файлик regions_countries_fill_match.csv для ручной чистки (регион-страна) \n\n# region <- read_csv(\"data/data_clean.csv\") %>% distinct(country, region)\n# df <- full_hand_org %>% distinct(country)\n#df <- left_join(df, region)\n#write_csv(df, \"regions_countries_fill_match.csv\")\n\n\ndata <- full_hand_org\n\n# пошел кусок из data_clean.R\n\ndata <- data %>% \n  mutate(year_group = case_when(year >= 1990 & year <= 2000 ~ \"1990-2000\",\n                                year >= 2001 & year <= 2010 ~ \"2001-2010\",\n                                year >= 2011 & year <= 2020 ~ \"2011-2020\",\n                                TRUE ~ as.character(year))) %>% \n  mutate(year_group = factor(year_group, levels = c(\"1990-2000\", \"2001-2010\",\"2011-2020\"))) \n\ndata <- data %>% mutate(field = gsub(\"\\\\['\", \"\", field),\n                        field = gsub(\"\\\\']\", \"\", field),\n                        field = gsub(\"\\\\', '\", \";\", field))\n\nussr_replace <- read_excel(\"/Users/elenachechik/Desktop/Russian_studies/data/organisation_full_names.xlsx\", \n                           sheet = \"для замены ussr\") %>% select(UT, country_unified) %>% distinct(UT, .keep_all = TRUE) %>% filter(country_unified != \"Russia\")\n\nregions_countries_fill_match <- read_delim(\"data/regions_countries_fill_match.csv\", \n    delim = \";\", escape_double = FALSE, trim_ws = TRUE)\n\nRows: 106 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (3): country, country_new, region_new\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# 1 Чистка стран и организаций\n\ndata <- data %>% # \n  left_join(ussr_replace, by = c(\"UT\"=\"UT\")) %>% \n  mutate(country = case_when(!is.na(country_unified) ~ country_unified,\n                             TRUE ~ country)) \n\ndata <- data %>% left_join(regions_countries_fill_match) \n\nJoining with `by = join_by(country)`\n\ndata <- data %>% select(-country) %>% \n  rename(region = region_new,\n         country = country_new)\n\ndata <- data %>% select(-country_unified)\n\ndata <- data %>% \n  mutate(country = case_when(is.na(country) ~ \"Unknown\",\n                             TRUE ~ country))\ndata <- data %>% \n  mutate(region = case_when(is.na(region) ~ \"Unknown\",\n                             TRUE ~ region))  \n\ndata <- data %>%\n  mutate(organisation_full = case_when(is.na(organisation_full) ~ \"Unknown\",\n                                       TRUE ~ organisation_full)) \n\n\n\nUT_org_replace <- read_delim(\"/Users/elenachechik/Desktop/Russian_studies/data/UT_org_replace.csv\",\n                             delim = \";\", escape_double = FALSE, col_names = FALSE,\n                             trim_ws = TRUE)\n\nRows: 25 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (2): X1, X2\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata <- data %>% \n  left_join(UT_org_replace, by = c(\"UT\"=\"X1\")) %>% \n  mutate(organisation_full = case_when(UT == \"WOS:000178643600036\" | UT == \"WOS:000455241900010\" ~ \"Unknown\",\n                                       !is.na(X2) & organisation_full == \"War College\" ~ X2,\n                                       UT == \"WOS:000337988000016\" ~ \"Unknown\",\n                                       UT == \"WOS:A1990EF84700009\" | UT == \"WOS:A1990EF84700001\" |\n                                         UT == \"WOS:A1991HK57400005\" ~ \"Unknown\",\n                                       TRUE ~ organisation_full)) %>% select(-X2) %>% \n  filter(organisation_full != \"Independent Researcher\") %>% \n  filter(organisation_full != \"U.S. Naval War College\") %>% \n  filter(organisation_full != \"Us Naval War College\")\n\n\n\n\n# Страны норм, но есть три вида РЭШа\n\n# Поэтому вменение моды будет бить не только универы тесок, но и микро задублированные универы. \n\n# Вменение моды стране через институцию\n\n\n## Делаем таблицу с модами \n\nmoda_table <- data %>% \n  group_by(organisation_full, country) %>% count() %>% ungroup() %>%\n  group_by(organisation_full) %>% mutate(n_count = length(country)) %>% ungroup() %>%\n  mutate(n = case_when(country == \"Unknown\" ~ as.numeric(0),\n                       TRUE ~ as.numeric(n))) %>% \n  group_by(organisation_full, n_count) %>%\n  mutate(country_2 = case_when(n == max(n) ~ country,\n                               TRUE ~ NA_character_)) %>% ungroup() %>%\n  filter(!is.na(country_2)) %>% select(organisation_full, country_2) %>% \n  distinct(organisation_full, .keep_all = TRUE)\n\n## цепляем к нашему датасету data_website original\ndata <- data %>% left_join(moda_table)\n\nJoining with `by = join_by(organisation_full)`\n\ndata <- data %>% mutate(country_3 = case_when(organisation_full == \"Unknown\" ~ country,\n                                              organisation_full == \"Unknown or Uni < 10\" ~ country,\n                                              TRUE ~ country_2))  \ndata <- data %>%\n  select(-country, -country_2) %>% \n  rename(country = country_3) \n\nreg <- regions_countries_fill_match %>% \n              select(country_new, region_new) %>% filter(!is.na(country_new)) %>% \n  rename(country = country_new,\n         region = region_new) %>% distinct(country, .keep_all = TRUE)\n\ndata <- data %>% select(-region) %>% \n  left_join(reg)\n\nJoining with `by = join_by(country)`\n\ndata <- data %>% \n  mutate(region = case_when(is.na(region) ~ \"Unknown\",\n                             TRUE ~ region))  \n\n## смотрим на \"грязь\" как в пункте (1) и сравниваем с новой переменной country_2\n\n# df <- data %>%\n#   group_by(organisation_full) %>%\n#   summarise(count = length(UT),\n#             # country_2 = paste(sort(unique(country_2)), collapse=\"; \"),\n#             country = paste(sort(unique(country)), collapse=\"; \")) %>%\n#   arrange(desc(count))\n\n\n\n## Недочищенные институции\n\ndata <-  data %>% \n  mutate(organisation_full = case_when(organisation_full == 'University Of Kentucky' ~ \"University of Kentucky\",\n                                       TRUE ~ organisation_full))\n\n\n\n\nwrite_csv(data, \n          \"/Users/elenachechik/Desktop/Russian_studies/data/full_hand_org.csv\")"
  }
]